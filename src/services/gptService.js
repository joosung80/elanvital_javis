/**
 * GPT ì„œë¹„ìŠ¤ - ëª¨ë“  GPT í˜¸ì¶œì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬
 */

const { getOpenAIClient, logOpenAICall } = require('../utils/openaiClient');
const { getGPTModel } = require('../config/models');

/**
 * GPT APIë¥¼ í˜¸ì¶œí•˜ëŠ” ê³µìš© í•¨ìˆ˜
 * @param {string} feature - ê¸°ëŠ¥ ì´ë¦„ (FEATURE_MODELSì˜ í‚¤)
 * @param {Array} messages - ë©”ì‹œì§€ ë°°ì—´ [{role: 'system', content: '...'}, {role: 'user', content: '...'}]
 * @param {Object} options - ì¶”ê°€ ì˜µì…˜
 * @param {number} options.temperature - ì˜¨ë„ (ê¸°ë³¸ê°’: 0.7)
 * @param {number} options.max_tokens - ìµœëŒ€ í† í° (ê¸°ë³¸ê°’: null)
 * @param {Object} options.response_format - ì‘ë‹µ í˜•ì‹ (ê¸°ë³¸ê°’: null)
 * @param {string} options.purpose - ë¡œê·¸ìš© ëª©ì  ì„¤ëª… (ê¸°ë³¸ê°’: feature)
 * @returns {Promise<Object>} GPT ì‘ë‹µ ê°ì²´
 */
async function callGPT(feature, messages, options = {}) {
    const {
        temperature = 0.7,
        max_tokens = null,
        response_format = null,
        purpose = feature
    } = options;

    try {
        const openai = getOpenAIClient();
        const model = getGPTModel(feature);

        // API í˜¸ì¶œ ì˜µì…˜ êµ¬ì„±
        const apiOptions = {
            model: model,
            messages: messages,
            temperature: temperature
        };

        // ì„ íƒì  ì˜µì…˜ ì¶”ê°€
        if (max_tokens) apiOptions.max_tokens = max_tokens;
        if (response_format) apiOptions.response_format = response_format;

        console.log(`ğŸ¤– GPT í˜¸ì¶œ: ${feature} (${model})`);
        
        const response = await openai.chat.completions.create(apiOptions);
        
        // ë¡œê·¸ ì¶œë ¥
        logOpenAICall(model, response.usage, purpose);
        
        return response;

    } catch (error) {
        console.error(`âŒ GPT í˜¸ì¶œ ì‹¤íŒ¨ (${feature}):`, error.message);
        throw error;
    }
}

/**
 * GPT ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ë§Œ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜
 * @param {Object} response - GPT ì‘ë‹µ ê°ì²´
 * @returns {string} ì‘ë‹µ í…ìŠ¤íŠ¸
 */
function extractContent(response) {
    return response.choices[0].message.content;
}

/**
 * GPT ì‘ë‹µì—ì„œ JSONì„ íŒŒì‹±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
 * @param {Object} response - GPT ì‘ë‹µ ê°ì²´
 * @returns {Object} íŒŒì‹±ëœ JSON ê°ì²´
 */
function extractJSON(response) {
    const content = extractContent(response);
    // ```json íƒœê·¸ ì œê±°
    const cleanContent = content.replace(/```json/g, '').replace(/```/g, '').trim();
    return JSON.parse(cleanContent);
}

/**
 * ê°„ë‹¨í•œ GPT í˜¸ì¶œ (í…ìŠ¤íŠ¸ ì‘ë‹µ)
 * @param {string} feature - ê¸°ëŠ¥ ì´ë¦„
 * @param {string} systemPrompt - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
 * @param {string} userPrompt - ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
 * @param {Object} options - ì¶”ê°€ ì˜µì…˜
 * @returns {Promise<string>} GPT ì‘ë‹µ í…ìŠ¤íŠ¸
 */
async function askGPT(feature, systemPrompt, userPrompt, options = {}) {
    const messages = [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
    ];
    
    const response = await callGPT(feature, messages, options);
    return extractContent(response);
}

/**
 * JSON ì‘ë‹µì„ ìš”ì²­í•˜ëŠ” GPT í˜¸ì¶œ
 * @param {string} feature - ê¸°ëŠ¥ ì´ë¦„
 * @param {string} systemPrompt - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
 * @param {string} userPrompt - ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
 * @param {Object} options - ì¶”ê°€ ì˜µì…˜
 * @returns {Promise<Object>} íŒŒì‹±ëœ JSON ê°ì²´
 */
async function askGPTForJSON(feature, systemPrompt, userPrompt, options = {}) {
    const messages = [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
    ];
    
    // JSON ì‘ë‹µ í˜•ì‹ ê°•ì œ
    const jsonOptions = {
        ...options,
        response_format: { type: "json_object" }
    };
    
    const response = await callGPT(feature, messages, jsonOptions);
    return extractJSON(response);
}

module.exports = {
    callGPT,
    extractContent,
    extractJSON,
    askGPT,
    askGPTForJSON
};
